# -*- coding: utf-8 -*-
"""Weight Initializations for Daniele.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OQx0bCc-EsLiPn8a8ex-mU2EkuQsnwPL

In [this notebook](https://drive.google.com/file/d/1HkfxbrKj9aRylTvVJdHsLvpGQGCTBLVL/view?usp=sharing) I was able to get (for a small qkeras model) totally reproducible training behavior + the desired results for equating gradient estimators with weight re-initialization (or no weight re-initialization for Adam). The notebook is messy, so I'm giving you some cleaner directions here.
"""

from tqdm import tqdm
from tensorflow.keras.regularizers import l2
import os
import sys
import pickle
import random
from tensorflow.keras import layers
from tensorflow import keras
from copy import deepcopy
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.optimizers.schedules import LearningRateSchedule
from tensorflow.keras import backend
import tensorflow.compat.v2 as tf
import math
from qkeras.qconvolutional import *
import pandas as pd
from matplotlib import pyplot as plt
from pprint import pprint
import json
from scipy.stats import pearsonr
from tensorflow.keras import initializers
from qkeras import BaseQuantizer
import numpy as np
import tensorflow as tf
import argparse
import importlib.util

notebook = False

"""# Gradient estimators and weight re-initialization functions

Here are some options for quantizers with special gradient estimators corresponding weight initialization functions. Here I just provide the remapping functions, and below I'll show how to get this into a deterministic weight initializer.

## Gradient Estimators
"""


def _compute_fans(shape):
  """Copied from keras github

  Computes the number of input and output units for a weight shape.

  Args:
    shape: Integer shape tuple or TF tensor shape.

  Returns:
    A tuple of integer scalars (fan_in, fan_out).
  """
  if len(shape) < 1:  # Just to avoid errors for constants.
    fan_in = fan_out = 1
  elif len(shape) == 1:
    fan_in = fan_out = shape[0]
  elif len(shape) == 2:
    fan_in = shape[0]
    fan_out = shape[1]
  else:
    # Assuming convolution kernels (2D, 3D, or more).
    # kernel shape: (..., input_depth, depth)
    receptive_field_size = 1
    for dim in shape[:-2]:
      receptive_field_size *= dim
    fan_in = shape[-2] * receptive_field_size
    fan_out = shape[-1] * receptive_field_size
  return int(fan_in), int(fan_out)


def get_he_uniform_max_val(shape):

  # return 1.0

  fan_in, _ = _compute_fans(shape)

  # Using max val from HeUniform:
  # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeUniform
  return np.sqrt(6.0 / (fan_in))


class ste_binary_quantizer(BaseQuantizer):

  def set_shape(self, _):
    pass

  @property
  def lr_adjustment(self):
    return 1.0

  @tf.custom_gradient
  def __call__(self, x):
    output = tf.where(x >= 0.0, tf.ones_like(x), -tf.ones_like(x))

    def grad(dy):
      return dy

    return output, grad


class tanh_binary_quantizer(BaseQuantizer):

  def __init__(self, k):
    self._k = k  # how sharp the tanh function is

  @property
  def k(self):
    return self._k / self.max_val

  def set_shape(self, shape):
    """set the shape of the input data"""

    max_val = get_he_uniform_max_val(shape)
    self.max_val = max_val

  @tf.custom_gradient
  def __call__(self, x):
    output = tf.where(x >= 0.0, tf.ones_like(x), -tf.ones_like(x))

    def grad(dy):
      return dy * self.k * (1 - tf.tanh(self.k * x) ** 2)

    return output, grad


class pwl_multi_bit_quantizer(BaseQuantizer):
  """Pwl quantizer to match the behavior of the dsq quantizer"""

  def __init__(self, bits, k, adjust_learning_rate):

    self.bits = bits
    self._k = k
    self.max_val = None
    self.adjust_learning_rate = adjust_learning_rate

  @property
  def k(self):
    return self._k / self.max_val

  @property
  def delta(self):
    return (2.0 * self.max_val) / (2.0 ** self.bits - 1)

  @property
  def interval_integral(self):

    s = 1 / tf.tanh(0.5 * self.k * self.delta)
    endpoint = self.k * self.delta / 2.0
    integral = (endpoint + tf.sinh(endpoint) * tf.cosh(endpoint)) / (s)
    integral = integral * 2.0 / (self.delta * (self.k ** 2))

    return integral

  @property
  def lr_adjustment(self):

    if self.adjust_learning_rate:
      return tf.keras.backend.cast_to_floatx(self.delta / self.interval_integral)
    else:
      return 1.0

  def set_shape(self, shape):
    """set the shape of the input data"""

    max_val = get_he_uniform_max_val(shape)
    self.max_val = max_val

  @tf.custom_gradient
  def __call__(self, x):

    def grad(dy):

      # absorbing lr adustment into gradient, since adjustment differs for different gradient estimators
      return self.lr_adjustment * dy * tf.where(tf.abs(x) < self.max_val, 1.0, 0.0)

    clipped = tf.clip_by_value(x, -self.max_val, self.max_val)
    quantized = self.delta * \
        tf.round((clipped + self.max_val) / self.delta) - self.max_val

    return quantized, grad


class dsq_multi_bit_quantizer(BaseQuantizer):

  def __init__(self, bits, k):
    """k is a parameter that determines how "sharp" the approximation is.
    The larger the value, the closer this is to the staircase function.
    k=2.5 is a reasonable value
    See https://arxiv.org/pdf/1908.05033.pdf.

    max_val determines the max absolute value of the representable range.
    I'd think that 3 would be a good value for gaussian distributed weights with
    mean 0 and standard deviation 1.
    """

    self.bits = bits
    self._k = k
    self.max_val = None

  @property
  def k(self):
    return self._k / self.max_val

  def set_shape(self, shape):
    """set the shape of the input data"""

    max_val = get_he_uniform_max_val(shape)
    self.max_val = max_val

  @tf.custom_gradient
  def __call__(self, x):

    delta = (2.0 * self.max_val) / (2.0 ** self.bits - 1)

    def grad(dy):
      i = tf.math.floor((x + self.max_val) / delta)
      m_i = -self.max_val + (i + 0.5) * delta
      s = 1.0 / tf.tanh(0.5 * self.k * delta)
      s = tf.keras.backend.cast_to_floatx(s)
      phi = s * self.k * (1 - tf.tanh(self.k * (x - m_i)) ** 2.0)

      phi = tf.where(tf.logical_and(
          x <= self.max_val, x >= -self.max_val), phi, 0)

      phi = phi * delta / 2.0

      return dy * phi

    clipped = tf.clip_by_value(x, -self.max_val, self.max_val)
    quantized = delta * \
        tf.round((clipped + self.max_val) / delta) - self.max_val

    return quantized, grad


"""## Initializers"""


class ste_initializer(initializers.Initializer):

  def __init__(self, seed):
    self.seed = seed
    self.base_initializer = initializers.HeUniform

  def remap(self, x):

    return x

  def __call__(self, shape, dtype=None):
    # seeding at every call for maximal determinism
    base_initializer = self.base_initializer(seed=self.seed)
    return base_initializer(shape, dtype)


class tanh_binary_initializer(initializers.Initializer):

  def __init__(self, seed, k):
    self.seed = seed
    self._k = k
    self.base_initializer = initializers.HeUniform

  @property
  def k(self):
    return self._k / self.max_val

  def remap(self, x):

    xk = x * self.k
    return (xk + tf.sinh(xk) * tf.cosh(xk)) / (2.0 * (self.k ** 2))

  def __call__(self, shape, dtype=None):
    self.max_val = get_he_uniform_max_val(shape)
    # seeding at every call for maximal determinism
    base_initializer = self.base_initializer(seed=self.seed)
    return self.remap(base_initializer(shape, dtype))


class dsq_multi_bit_initializer(initializers.Initializer):

  def __init__(self, seed, bits, k):
    self.seed = seed
    self.base_initializer = initializers.HeUniform
    self.bits = bits
    self._k = k
    self.max_val = None

  @property
  def k(self):
    return self._k / self.max_val

  @property
  def delta(self):

    return (2.0 * self.max_val) / (2.0 ** self.bits - 1)

  @property
  def interval_integral(self):

    s = 1.0 / tf.tanh(0.5 * self.k * self.delta)
    s = tf.keras.backend.cast_to_floatx(s)
    endpoint = self.k * self.delta / 2.0
    endpoint = tf.keras.backend.cast_to_floatx(endpoint)

    integral = (endpoint + tf.sinh(endpoint) * tf.cosh(endpoint)) / (s)
    integral = integral * 2.0 / (self.delta * (self.k ** 2))

    return tf.keras.backend.cast_to_floatx(integral)

  @property
  def lr_adjustment(self):

    return self.delta / self.interval_integral

  def remap(self, x):

    i = tf.floor((x + self.max_val) / self.delta)

    zero_point = tf.math.floor((2.0 ** self.bits - 1) / 2.0)
    centered_i = i - zero_point
    base_point = self.interval_integral * centered_i

    m_i = -self.max_val + (i + 0.5) * self.delta
    s = tf.keras.backend.cast_to_floatx(
        1.0 / tf.tanh(0.5 * self.k * self.delta))
    endpoint = self.k * (x - m_i)
    increment = (endpoint + tf.sinh(endpoint) * tf.cosh(endpoint)) / s
    increment = increment / (self.delta * (self.k ** 2))

    integral = base_point + increment

    remap_val = self.lr_adjustment * integral

    return remap_val

  def __call__(self, shape, dtype=None):

    self.max_val = get_he_uniform_max_val(shape)
    # seeding at every call for maximal determinism
    base_initializer = self.base_initializer(seed=self.seed)
    return self.remap(base_initializer(shape, dtype))


"""## Some tests, for safety"""


def test_quantizer_and_initializer(
        quantizer, initializer, seed, shape, adjust_learning_rate, *args):

  initializer = initializer(seed, *args)
  # call initializer to set the shape
  _ = initializer(shape)

  max_val = get_he_uniform_max_val(shape)

  quantizer = quantizer(*args)
  quantizer.set_shape(shape)

  if adjust_learning_rate:
    args = list(args)
    args.append(True)
    pwl_quantizer = pwl_multi_bit_quantizer(*args)
    pwl_quantizer.set_shape(shape)
    lr_adjustment = pwl_quantizer.lr_adjustment

  else:
    lr_adjustment = 1.0

  inputs = np.linspace(-max_val, max_val, 10001)
  # inputs = [-3, -2, -1, 0, 1, 2, 3, 4]
  x = tf.Variable(tf.keras.backend.cast_to_floatx(inputs))

  xq = quantizer(x).numpy()

  unique_sorted_arr = np.sort(np.unique(xq))

  # Get halfway values
  boundary_points = (unique_sorted_arr[:-1] + unique_sorted_arr[1:]) / 2

  # make sure that quantizer
  if not np.allclose(boundary_points, initializer.remap(boundary_points), atol=0.001):
    import pdb
    pdb.set_trace()

  # Get derivative of q(x) w.r.t. x
  with tf.GradientTape() as tape:
    tape.watch(x)
    y = quantizer(x)

  dy_dx = tape.gradient(y, x)
  inv_integral_dy_dx = tf.cumsum((1 / dy_dx) * (inputs[1] - inputs[0]))
  zero_point = np.argmin(inputs ** 2)
  if not np.isclose(inputs[zero_point], 0):
    import pdb
    pdb.set_trace()

  inv_integral_dy_dx -= inv_integral_dy_dx[zero_point]

  remap_vals = lr_adjustment * inv_integral_dy_dx

  inputs = tf.keras.backend.cast_to_floatx(inputs)

  if not np.allclose(remap_vals, initializer.remap(inputs).numpy(), rtol=0.02, atol=.02):
    import pdb
    pdb.set_trace()


if notebook:

  quantizer = tanh_binary_quantizer
  initializer = tanh_binary_initializer
  base_initializer = initializers.RandomUniform
  seed = 1
  shape = (10, 9, 8, 7)
  base_initializer_kwargs = {'minval': -1, 'maxval': 1}
  adjust_learning_rate = False

  for k in [1, 2, 3.5]:
    test_quantizer_and_initializer(
        quantizer, initializer, seed, shape, adjust_learning_rate, k)

  quantizer = dsq_multi_bit_quantizer
  initializer = dsq_multi_bit_initializer
  seed = 1
  adjust_learning_rate = True

  for shape in [(1, ), (10, ), (10, 9), (10, 9, 8, 7)]:
    for bits in [2, 3, 4]:
      for k in [1, 2, 3.5, 5]:
        test_quantizer_and_initializer(
            quantizer, initializer, seed, shape, adjust_learning_rate, bits, k)

"""### Some plots to help the intuition

"""


if notebook:
  shape = (10, 3, 3, 3)

  max_val = get_he_uniform_max_val(shape)
  bits = 1
  k = 2.5
  binary = False
  if binary:
    q = tanh_binary_quantizer(k=k)
    lr_adjustment = 1.0
    max_val = 1.0
  else:
    q = dsq_multi_bit_quantizer(bits=bits, k=k)
    pwl_quantizer = pwl_multi_bit_quantizer(
        bits=bits, k=k, adjust_learning_rate=True)
    pwl_quantizer.set_shape(shape)
    lr_adjustment = pwl_quantizer.lr_adjustment

  q.set_shape(shape)

  N = 1000
  inputs = np.linspace(-max_val * 1.2, max_val * 1.2, 2 * N + 1)

  x = tf.Variable(tf.keras.backend.cast_to_floatx(inputs))

  # Get derivative of q(x) w.r.t. x
  with tf.GradientTape() as tape:
    tape.watch(x)
    y = q(x)

  dy_dx = tape.gradient(y, x)

  integral_dy_dx = tf.cumsum(dy_dx * (inputs[1] - inputs[0])) - max_val

  pos_dy_dx = dy_dx[dy_dx > 0]
  pos_dy_dx_inputs = tf.keras.backend.cast_to_floatx(inputs[dy_dx > 0])
  inv_integral_dy_dx = tf.cumsum((1.0 / pos_dy_dx) * (inputs[1] - inputs[0]))
  inv_integral_dy_dx -= inv_integral_dy_dx[len(inv_integral_dy_dx) // 2]
  if binary:
    initializer = tanh_binary_initializer(seed, k)
  else:
    initializer = dsq_multi_bit_initializer(seed, bits, k)

  _ = initializer(shape)

  remapped_inputs = initializer.remap(pos_dy_dx_inputs)

  remapped_inputs = remapped_inputs / lr_adjustment

  # plt.plot(inputs, q(inputs), label='q(x)')
  plt.plot(inputs, dy_dx, label='q\'(x)')
  plt.plot(inputs, integral_dy_dx, label='$\int$ q\'(x)')
  # plt.plot(inputs[dy_dx > 0], inv_integral_dy_dx, label='$\int$ 1 / q\'(x)')
  # plt.plot(inputs[dy_dx > 0], remapped_inputs, label='Remapped inputs')
  title = 'tanh quantizer' if binary else 'DSQ quantizer'
  plt.title(title + ', k = ' + str(k))
  plt.legend()
  plt.show()

"""# QConv2DClean"""


class QConv2DClean(Conv2D, PrunableLayer):
  """2D convolution layer (e.g. spatial convolution over images).

  Removed initialization and clipping logic for this study only
  """

  def __init__(self,
               filters,
               kernel_size,
               strides=(1, 1),
               padding="valid",
               data_format="channels_last",
               dilation_rate=(1, 1),
               activation=None,
               use_bias=True,
               kernel_initializer="he_normal",
               bias_initializer="zeros",
               kernel_regularizer=None,
               bias_regularizer=None,
               activity_regularizer=None,
               kernel_constraint=None,
               bias_constraint=None,
               kernel_range=None,
               bias_range=None,
               kernel_quantizer=None,
               bias_quantizer=None,
               debug=False,
               **kwargs):

    if kernel_range is not None:
      warnings.warn("kernel_range is deprecated in QConv2D layer.")

    if bias_range is not None:
      warnings.warn("bias_range is deprecated in QConv2D layer.")

    self.kernel_range = kernel_range
    self.bias_range = bias_range

    self.debug = debug

    self.kernel_quantizer = kernel_quantizer
    self.bias_quantizer = bias_quantizer

    self.kernel_quantizer_internal = get_quantizer(self.kernel_quantizer)
    self.bias_quantizer_internal = get_quantizer(self.bias_quantizer)

    # optimize parameter set to "auto" scaling mode if possible
    if hasattr(self.kernel_quantizer_internal, "_set_trainable_parameter"):
      self.kernel_quantizer_internal._set_trainable_parameter()

    self.quantizers = [
        self.kernel_quantizer_internal, self.bias_quantizer_internal
    ]

    # Removing constraint and initializer logic

    # kernel_constraint, kernel_initializer = (
    #     get_auto_range_constraint_initializer(self.kernel_quantizer_internal,
    #                                           kernel_constraint,
    #                                           kernel_initializer))

    # if use_bias:
    #   bias_constraint, bias_initializer = (
    #       get_auto_range_constraint_initializer(self.bias_quantizer_internal,
    #                                             bias_constraint,
    #                                             bias_initializer))

    if activation is not None:
      activation = get_quantizer(activation)

    super(QConv2DClean, self).__init__(
        filters=filters,
        kernel_size=kernel_size,
        strides=strides,
        padding=padding,
        data_format=data_format,
        dilation_rate=dilation_rate,
        activation=activation,
        use_bias=use_bias,
        kernel_initializer=kernel_initializer,
        bias_initializer=bias_initializer,
        kernel_regularizer=kernel_regularizer,
        bias_regularizer=bias_regularizer,
        activity_regularizer=activity_regularizer,
        kernel_constraint=kernel_constraint,
        bias_constraint=bias_constraint,
        **kwargs)

  def call(self, inputs):
    if self.kernel_quantizer:
      quantized_kernel = self.kernel_quantizer_internal(self.kernel)
      if self.debug:
        tf.print('kernel:', self.kernel)
    else:
      quantized_kernel = self.kernel

    outputs = tf.keras.backend.conv2d(
        inputs,
        quantized_kernel,
        strides=self.strides,
        padding=self.padding,
        data_format=self.data_format,
        dilation_rate=self.dilation_rate)

    if self.use_bias:
      if self.bias_quantizer:
        quantized_bias = self.bias_quantizer_internal(self.bias)
      else:
        quantized_bias = self.bias

      outputs = tf.keras.backend.bias_add(
          outputs, quantized_bias, data_format=self.data_format)

    if self.activation is not None:
      return self.activation(outputs)
    return outputs

  def get_config(self):
    config = {
        "kernel_quantizer": constraints.serialize(
            self.kernel_quantizer_internal
        ),
        "bias_quantizer": constraints.serialize(
            self.bias_quantizer_internal
        ),
        "kernel_range": self.kernel_range,
        "bias_range": self.bias_range,
    }
    base_config = super(QConv2D, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))

  def get_quantization_config(self):
    return {
        "kernel_quantizer":
            str(self.kernel_quantizer_internal),
        "bias_quantizer":
            str(self.bias_quantizer_internal),
        "activation":
            str(self.activation),
        "filters": str(self.filters)
    }

  def get_quantizers(self):
    return self.quantizers

  def get_prunable_weights(self):
    return [self.kernel]

  def build(self, shape):

    super().build(shape)

    if self.use_bias:
      self.bias_quantizer_internal.set_shape(self.bias.shape)
    self.kernel_quantizer_internal.set_shape(self.kernel.shape)


"""# Updated Cosine Learning rate scheduler (copied from recent keras release)"""


class CosineDecay(LearningRateSchedule):
  """A LearningRateSchedule that uses a cosine decay with optional warmup.

  See [Loshchilov & Hutter, ICLR2016](https://arxiv.org/abs/1608.03983),
  SGDR: Stochastic Gradient Descent with Warm Restarts.

  For the idea of a linear warmup of our learning rate,
  see [Goyal et al.](https://arxiv.org/pdf/1706.02677.pdf).

  When we begin training a model, we often want an initial increase in our
  learning rate followed by a decay. If `warmup_target` is an int, this
  schedule applies a linear increase per optimizer step to our learning rate
  from `initial_learning_rate` to `warmup_target` for a duration of
  `warmup_steps`. Afterwards, it applies a cosine decay function taking our
  learning rate from `warmup_target` to `alpha` for a duration of
  `decay_steps`. If `warmup_target` is None we skip warmup and our decay
  will take our learning rate from `initial_learning_rate` to `alpha`.
  It requires a `step` value to  compute the learning rate. You can
  just pass a TensorFlow variable that you increment at each training step.

  The schedule is a 1-arg callable that produces a warmup followed by a
  decayed learning rate when passed the current optimizer step. This can be
  useful for changing the learning rate value across different invocations of
  optimizer functions.

  Our warmup is computed as:

  ```python
  def warmup_learning_rate(step):
      completed_fraction = step / warmup_steps
      total_delta = target_warmup - initial_learning_rate
      return completed_fraction * total_delta
  ```

  And our decay is computed as:

  ```python
  if warmup_target is None:
      initial_decay_lr = initial_learning_rate
  else:
      initial_decay_lr = warmup_target

  def decayed_learning_rate(step):
      step = min(step, decay_steps)
      cosine_decay = 0.5 * (1 + cos(pi * step / decay_steps))
      decayed = (1 - alpha) * cosine_decay + alpha
      return initial_decay_lr * decayed
  ```

  Example usage without warmup:

  ```python
  decay_steps = 1000
  initial_learning_rate = 0.1
  lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(
      initial_learning_rate, decay_steps)
  ```

  Example usage with warmup:

  ```python
  decay_steps = 1000
  initial_learning_rate = 0
  warmup_steps = 1000
  target_learning_rate = 0.1
  lr_warmup_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(
      initial_learning_rate, decay_steps, warmup_target=target_learning_rate,
      warmup_steps=warmup_steps
  )
  ```

  You can pass this schedule directly into a `tf.keras.optimizers.Optimizer`
  as the learning rate. The learning rate schedule is also serializable and
  deserializable using `tf.keras.optimizers.schedules.serialize` and
  `tf.keras.optimizers.schedules.deserialize`.

  Returns:
    A 1-arg callable learning rate schedule that takes the current optimizer
    step and outputs the decayed learning rate, a scalar `Tensor` of the same
    type as `initial_learning_rate`.
  """

  def __init__(
      self,
      initial_learning_rate,
      decay_steps,
      alpha=0.0,
      name=None,
      warmup_target=None,
      warmup_steps=0,
  ):
    """Applies cosine decay to the learning rate.

    Args:
      initial_learning_rate: A scalar `float32` or `float64` `Tensor` or a
        Python int. The initial learning rate.
      decay_steps: A scalar `int32` or `int64` `Tensor` or a Python int.
        Number of steps to decay over.
      alpha: A scalar `float32` or `float64` `Tensor` or a Python int.
        Minimum learning rate value for decay as a fraction of
        `initial_learning_rate`.
      name: String. Optional name of the operation.  Defaults to
        'CosineDecay'.
      warmup_target: None or a scalar `float32` or `float64` `Tensor` or a
        Python int. The target learning rate for our warmup phase. Will cast
        to the `initial_learning_rate` datatype. Setting to None will skip
        warmup and begins decay phase from `initial_learning_rate`.
        Otherwise scheduler will warmup from `initial_learning_rate` to
        `warmup_target`.
      warmup_steps: A scalar `int32` or `int64` `Tensor` or a Python int.
        Number of steps to warmup over.
    """
    super().__init__()

    self.initial_learning_rate = initial_learning_rate
    self.decay_steps = decay_steps
    self.alpha = alpha
    self.name = name
    self.warmup_steps = warmup_steps
    self.warmup_target = warmup_target

  def _decay_function(self, step, decay_steps, decay_from_lr, dtype):
    with tf.name_scope(self.name or "CosineDecay"):
      completed_fraction = step / decay_steps
      tf_pi = tf.constant(math.pi, dtype=dtype)
      cosine_decayed = 0.5 * (1.0 + tf.cos(tf_pi * completed_fraction))
      decayed = (1 - self.alpha) * cosine_decayed + self.alpha
      return tf.multiply(decay_from_lr, decayed)

  def _warmup_function(
      self, step, warmup_steps, warmup_target, initial_learning_rate
  ):
    with tf.name_scope(self.name or "CosineDecay"):
      completed_fraction = step / warmup_steps
      total_step_delta = warmup_target - initial_learning_rate
      return total_step_delta * completed_fraction + initial_learning_rate

  def __call__(self, step):
    with tf.name_scope(self.name or "CosineDecay"):
      initial_learning_rate = tf.convert_to_tensor(
          self.initial_learning_rate, name="initial_learning_rate"
      )
      dtype = initial_learning_rate.dtype
      decay_steps = tf.cast(self.decay_steps, dtype)
      global_step_recomp = tf.cast(step, dtype)

      if self.warmup_target is None:
        global_step_recomp = tf.minimum(global_step_recomp, decay_steps)
        return self._decay_function(
            global_step_recomp,
            decay_steps,
            initial_learning_rate,
            dtype,
        )

      warmup_target = tf.cast(self.warmup_target, dtype)
      warmup_steps = tf.cast(self.warmup_steps, dtype)

      global_step_recomp = tf.minimum(
          global_step_recomp, decay_steps + warmup_steps
      )

      return tf.cond(
          global_step_recomp < warmup_steps,
          lambda: self._warmup_function(
              global_step_recomp,
              warmup_steps,
              warmup_target,
              initial_learning_rate,
          ),
          lambda: self._decay_function(
              global_step_recomp - warmup_steps,
              decay_steps,
              warmup_target,
              dtype,
          ),
      )

  def get_config(self):
    return {
        "initial_learning_rate": self.initial_learning_rate,
        "decay_steps": self.decay_steps,
        "alpha": self.alpha,
        "name": self.name,
        "warmup_target": self.warmup_target,
        "warmup_steps": self.warmup_steps,
    }


"""# Change point tracker callback"""


class QuantizeChangePointCallback(Callback):
  def __init__(self, quantize_func):
    super().__init__()
    self.quantize_func = quantize_func
    self.total_batches = 0  # Initialize total_batches to zero
    self.change_points = {}
    self.last_quantize = {}

  def get_change_point_data(self, points_changed_tensor, raw_weights, qweights):

    coords = tf.where(points_changed_tensor)
    coords_float = tf.cast(coords, dtype=tf.float32)
    true_values = tf.gather_nd(raw_weights, coords)
    quantized_values = tf.gather_nd(qweights, coords)
    batch_tensor = tf.fill([tf.shape(coords)[0]], self.total_batches)
    batch_tensor_float = tf.cast(batch_tensor, dtype=tf.float32)

    concat_input = [
        coords_float,
        tf.expand_dims(quantized_values, axis=-1),
        tf.expand_dims(batch_tensor_float, axis=-1),
    ]

    result_tensor = tf.concat(concat_input, axis=1)

    return result_tensor

  def on_train_begin(self, logs=None):

    # Loop through all weights except the last two
    for i, weight in enumerate(self.model.weights[:-2]):
      self.change_points[i] = []
      self.quantize_func.set_shape(weight.shape)
      self.last_quantize[i] = self.quantize_func(weight)
      points_changed_tensor = tf.ones_like(weight, dtype=tf.bool)
      change_point_data = self.get_change_point_data(
          points_changed_tensor, weight, self.last_quantize[i]
      )
      self.change_points[i].append(change_point_data)

  def on_batch_end(self, batch, logs=None):
    self.total_batches += 1  # Increment the total_batches counter

    # Loop through all weights except the last two
    for i, weight in enumerate(self.model.weights[:-2]):

      qweights = self.quantize_func(weight)
      points_changed_tensor = tf.math.logical_not(
          tf.experimental.numpy.isclose(qweights, self.last_quantize[i]))
      change_point_data = self.get_change_point_data(
          points_changed_tensor, weight, qweights
      )
      self.change_points[i].append(change_point_data)
      self.last_quantize[i] = qweights


"""# Weight Saver Callback"""


class StoreWeightsCallback(Callback):
  """Tracks weights and weight distances. Ignores the last two layers, as they are unquantized"""

  def __init__(self, epochs_interval):
    super().__init__()
    self.epochs_interval = epochs_interval
    self.stored_weights = {}
    self.stored_distances = {}  # To store the distance traveled at each epoch
    self.distance_traveled = 0.0  # Initialize distance_traveled attribute as a scalar
    self.prev_weights = None  # To store the previous weights for distance calculation

  def on_train_begin(self, logs=None):
    # Initialize distance_traveled as 0.0 at the beginning of training
    self.distance_traveled = 0.0

  def on_epoch_end(self, epoch, logs=None):
    if (epoch + 1) % self.epochs_interval == 0:
      self.stored_weights[epoch + 1] = self.model.get_weights()[:-2]
      # Store the current distance_traveled
      self.stored_distances[epoch + 1] = self.distance_traveled

  def on_batch_end(self, batch, logs=None):
    # Get the current weights
    current_weights = self.model.get_weights()
    # If prev_weights is None, initialize it with the current weights
    if self.prev_weights is None:
      self.prev_weights = current_weights
    # Calculate the sum of absolute differences for all weights and update distance_traveled
    for curr_w, prev_w in zip(current_weights[:-2], self.prev_weights[:-2]):
      max_val = get_he_uniform_max_val(curr_w.shape)
      self.distance_traveled += tf.reduce_sum(
          tf.math.abs(curr_w - prev_w) / max_val)
    # Update prev_weights with current_weights for the next batch
    self.prev_weights = current_weights


"""# Training"""


def train_model_simple(initializer, quantizer, learning_rate, optimizer, *,
                       straight_initializer, optimizer_kwargs, epochs=10, lr_kwargs):

  # set seeds
  np.random.seed(42)
  tf.random.set_seed(42)

  quantizer_callback = QuantizeChangePointCallback(quantizer)
  epochs_interval = 10
  weight_saver_callback = StoreWeightsCallback(epochs_interval)

  optimizer_kwargs = {} if not optimizer_kwargs else optimizer_kwargs

  # download data from mnist
  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

  # channel_scale = 16
  channel_scale = 1

  inputs = keras.Input(shape=(28, 28, 1))
  x = layers.experimental.preprocessing.Rescaling(1. / 255)(inputs)
  x = QConv2DClean(
      filters=1, kernel_size=1, kernel_quantizer=deepcopy(quantizer),
      kernel_initializer=initializer,
      use_bias=False,
      bias_initializer=initializer, debug=True)(x)

  x = QConv2DClean(
      filters=1, kernel_size=2, kernel_quantizer=deepcopy(quantizer),
      kernel_initializer=initializer,
      use_bias=False,
      bias_initializer=initializer, debug=True)(x)

  x = layers.Flatten()(x)
  x = layers.Dense(10, kernel_initializer=straight_initializer,
                   bias_initializer=straight_initializer)(x)
  outputs = layers.Activation("softmax", name="softmax")(x)
  model = keras.Model(inputs=inputs, outputs=outputs)

  weights_init = [weight.numpy() for weight in model.weights]

  opt = optimizer(learning_rate=learning_rate, **optimizer_kwargs)

  model.compile(optimizer=opt,
                loss="sparse_categorical_crossentropy",
                metrics=["accuracy"])

  steps_per_epoch = 1
  batch_size = 1
  # steps_per_epoch = 100
  # batch_size = 100
  validation_data = None

  callbacks = [quantizer_callback, weight_saver_callback]

  history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,
                      validation_data=validation_data, shuffle=False,
                      steps_per_epoch=steps_per_epoch, callbacks=callbacks)

  # weights_final = [weight.numpy() for weight in model.weights]
  weights_final = model.weights

  model_predictions = model.predict(x_test)

  res = {
      'history': history.history,
      'weights_init': weights_init,
      'weights_final': weights_final,
      'change_points': quantizer_callback.change_points,
      'total_batches': quantizer_callback.total_batches,
      'stored_weights': weight_saver_callback.stored_weights,
      'distance_traveled': weight_saver_callback.distance_traveled,
      'stored_distances': weight_saver_callback.stored_distances,
      'correct_output_values': y_test,  # Add the correct output values
      'model_predictions': model_predictions  # Add the model's predictions
  }

  return res


# Assuming QConv2DClean, QuantizeChangePointCallback, StoreWeightsCallback are defined elsewhere


def train_model_complex(
    initializer, quantizer, learning_rate, optimizer, *, 
    straight_initializer, optimizer_kwargs, steps_per_epoch, weight_decay=0.0, epochs=10, 
    lr_kwargs=None):

  # Begin argument pre-processing

  # Create an L2 regularizer with the given weight decay
  regularizer = l2(weight_decay)

  if isinstance(learning_rate, float):
    assert lr_kwargs is None
  else:
    assert isinstance(lr_kwargs, dict)
    learning_rate = learning_rate(**lr_kwargs)

  optimizer_kwargs = {} if not optimizer_kwargs else optimizer_kwargs

  quantizer_callback = QuantizeChangePointCallback(quantizer)
  epochs_interval = 10
  weight_saver_callback = StoreWeightsCallback(epochs_interval)

  opt = optimizer(learning_rate=learning_rate, **optimizer_kwargs)

  # End argument pre-processing

  # set seeds
  np.random.seed(42)
  tf.random.set_seed(42)

  # download data from mnist
  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

  x_train = x_train.astype('float32') / 255.0
  x_test = x_test.astype('float32') / 255.0
  # channel_scale = 16
  channel_scale = 1

  inputs = keras.Input(shape=(28, 28, 1))

  # Modify each layer to include the regularizer
  x = QConv2DClean(
      filters=32 * channel_scale, kernel_size=3, kernel_quantizer=deepcopy(quantizer),
      bias_quantizer=deepcopy(quantizer), kernel_initializer=initializer,
      bias_initializer=initializer, kernel_regularizer=regularizer,  # Add regularizer here
      bias_regularizer=regularizer,  # And here
      debug=False)(inputs)

  x = layers.Activation('relu')(x)
  x = layers.MaxPooling2D(pool_size=2)(x)

  x = QConv2DClean(
      filters=64 * channel_scale, kernel_size=3, kernel_quantizer=deepcopy(quantizer),
      bias_quantizer=deepcopy(quantizer), kernel_initializer=initializer,
      bias_initializer=initializer, kernel_regularizer=regularizer,  # Add regularizer here
      bias_regularizer=regularizer,  # And here
      debug=False)(x)

  x = layers.Activation('relu')(x)
  x = layers.MaxPooling2D(pool_size=2)(x)

  x = QConv2DClean(
      filters=128 * channel_scale, kernel_size=3, kernel_quantizer=deepcopy(quantizer),
      bias_quantizer=deepcopy(quantizer), kernel_initializer=initializer,
      bias_initializer=initializer, kernel_regularizer=regularizer,  # Add regularizer here
      bias_regularizer=regularizer,  # And here
      debug=False)(x)

  x = layers.Activation('relu')(x)
  x = layers.MaxPooling2D(pool_size=2)(x)

  x = layers.Flatten()(x)

  x = layers.Dense(10, kernel_initializer=straight_initializer,
                   bias_initializer=straight_initializer,
                   kernel_regularizer=regularizer,  # Add regularizer here
                   bias_regularizer=regularizer  # And here
                   )(x)

  outputs = layers.Activation("softmax", name="softmax")(x)
  model = keras.Model(inputs=inputs, outputs=outputs)

  weights_init = [weight.numpy() for weight in model.weights]

  model.compile(optimizer=opt,
                loss="sparse_categorical_crossentropy",
                metrics=["accuracy"])

  callbacks = [quantizer_callback, weight_saver_callback]

  history = model.fit(x_train, y_train, epochs=epochs, batch_size=128,
                      validation_data=(x_test, y_test), shuffle=False,
                      steps_per_epoch=steps_per_epoch, callbacks=callbacks)

  weights_final = model.weights

  model_predictions = model.predict(x_test)

  res = {
      'history': history.history,
      'weights_init': weights_init,
      'weights_final': weights_final,
      'change_points': quantizer_callback.change_points,
      'total_batches': quantizer_callback.total_batches,
      'stored_weights': weight_saver_callback.stored_weights,
      'distance_traveled': weight_saver_callback.distance_traveled,
      'stored_distances': weight_saver_callback.stored_distances,
      'correct_output_values': y_test,
      'model_predictions': model_predictions
  }

  return res


def train_model(*args, simple=True, **kwargs):
  if simple:
    return train_model_simple(*args, **kwargs)
  else:
    return train_model_complex(*args, **kwargs)

# from functools import lru_cache

# @lru_cache()


def train_corresponding_models(*, learning_rate, epochs, optimizer, binary,
                               k, bits, steps_per_epoch,
                               warp_initialize=False, simple=True, optimizer_kwargs=None,
                               lr_kwargs=None, weight_decay=0.0):
  """Get histories for both the Standard initializer with the tanh gradient and
  the warped initializer with the STE gradient"""

  seed = 42

  # get quantizers
  if binary:
    warp_quantizer = tanh_binary_quantizer(k)
    straight_quantizer = ste_binary_quantizer()
  else:
    warp_quantizer = dsq_multi_bit_quantizer(bits, k)
    # print('Revert this!')
    # warp_quantizer = pwl_multi_bit_quantizer(bits, max_val)
    straight_quantizer = pwl_multi_bit_quantizer(
        bits, k, adjust_learning_rate=warp_initialize)

  # get initializers
  if warp_initialize:
    if binary:
      warp_initializer = tanh_binary_initializer(seed, k)
    else:
      warp_initializer = dsq_multi_bit_initializer(seed, bits, k)
  else:
    warp_initializer = ste_initializer(seed)

  straight_initializer = ste_initializer(seed)

  # get quantizer warp model data
  quantizer_warp_data = train_model(
      straight_initializer,
      warp_quantizer,
      learning_rate,
      optimizer, epochs=epochs,
      straight_initializer=straight_initializer,
      simple=simple,
      optimizer_kwargs=optimizer_kwargs,
      weight_decay=weight_decay,
      lr_kwargs=lr_kwargs,
      steps_per_epoch=steps_per_epoch,)
  # get initializer warp model data
  initializer_warp_data = train_model(
      warp_initializer,
      straight_quantizer,
      learning_rate,
      optimizer, epochs=epochs,
      straight_initializer=straight_initializer,
      simple=simple,
      optimizer_kwargs=optimizer_kwargs,
      weight_decay=weight_decay,
      lr_kwargs=lr_kwargs,
      steps_per_epoch=steps_per_epoch,)

  return quantizer_warp_data, initializer_warp_data


"""# Change point calculations"""


def remove_elements_dataframe(df):
  stack = []
  oscillation_count = []
  final_df_list = []

  for index, row in df.iterrows():
    stack.append(row)
    # Initialize oscillation_count for the new element
    oscillation_count.append(0)

    # Check if the last four elements on the stack form a palindrome based on 'qvalue'
    while len(stack) >= 4 and stack[-1]['qvalue'] == stack[-3]['qvalue'] and stack[-2]['qvalue'] == stack[-4]['qvalue']:
      # Increment the oscillation_count for the first element in the palindrome
      oscillation_count[-4] += 1

      # Remove the middle two elements from the stack
      last_elt = stack.pop()
      _ = stack.pop()
      _ = stack.pop()

      _ = oscillation_count.pop()
      _ = oscillation_count.pop()
      _ = oscillation_count.pop()

      # Reset the oscillation_count for the new last element
      stack.append(last_elt)
      oscillation_count.append(0)

  # Add the remaining elements and their oscillation_count to the final list
  for row, count in zip(stack, oscillation_count):
    final_row = row.copy()
    final_row['oscillation_count'] = count
    final_df_list.append(final_row)

  # Create the final DataFrame
  final_df = pd.DataFrame(final_df_list)
  return final_df


def organize_change_point_data(change_points):

  organized_change_points = {}

  for i, change_point_data in (change_points.items()):
    organized_change_points[i] = {}

    aggregated = tf.concat(change_point_data, axis=0)
    shape = aggregated.shape
    length = shape[-1]

    coordinate_cols = [f'c{i}' for i in range(length - 2)]
    columns = coordinate_cols + ['qvalue', 'step_count']

    aggregated = pd.DataFrame(aggregated.numpy(), columns=columns)

    organized_change_points[i] = aggregated

  return organized_change_points


def compare_change_point_data(quantizer_warp_cps, initializer_warp_cps):

  quantizer_warp_cps = organize_change_point_data(quantizer_warp_cps)
  initializer_warp_cps = organize_change_point_data(initializer_warp_cps)

  assert quantizer_warp_cps.keys() == initializer_warp_cps.keys()

  total_weights = 0
  correct_weight_sequences = 0
  total_q_oscillation = 0
  total_i_oscillation = 0
  total_oscillation_error = 0
  total_step_count_error = 0
  total_compressed_change_points = 0

  exact_correct_weight_sequences = 0
  total_exact_step_count_error = 0
  total_exact_change_points = 0

  for (i, qcps), (_, icps) in tqdm(list(zip(quantizer_warp_cps.items(), initializer_warp_cps.items()))):

    assert qcps.shape[-1] == icps.shape[-1]
    length = qcps.shape[-1]
    coordinate_cols = [f'c{i}' for i in range(length - 2)]

    pd.testing.assert_frame_equal(
        qcps[coordinate_cols].drop_duplicates(),
        icps[coordinate_cols].drop_duplicates()
    )

    for (qcols, qsequence), (icols, isequence) in (zip(qcps.groupby(coordinate_cols), icps.groupby(coordinate_cols))):

      assert qcols == icols
      total_weights += 1

      compressed_qsequence = remove_elements_dataframe(
          qsequence).reset_index(drop=True)
      compressed_isequence = remove_elements_dataframe(
          isequence).reset_index(drop=True)

      correct_sequence = (
          (compressed_qsequence.shape == compressed_isequence.shape)
          and np.allclose(compressed_qsequence['qvalue'], compressed_isequence['qvalue'])
      )

      exact_correct_sequence = (
          (qsequence.shape == isequence.shape)
          and np.allclose(qsequence['qvalue'], isequence['qvalue'])
      )


      if correct_sequence:
        correct_weight_sequences += 1
        total_q_oscillation += compressed_qsequence['oscillation_count'].sum()
        total_i_oscillation += compressed_isequence['oscillation_count'].sum()
        total_step_count_error += np.abs(
            compressed_qsequence['step_count'] - compressed_isequence['step_count']).sum()
        total_oscillation_error += np.abs(
            compressed_qsequence['oscillation_count'] - compressed_isequence['oscillation_count']).sum()
        assert len(compressed_qsequence) > 0
        total_compressed_change_points += (len(compressed_qsequence) - 1)

      if exact_correct_sequence:
        exact_correct_weight_sequences += 1
        total_exact_step_count_error += np.abs(
            qsequence['step_count'] - isequence['step_count']).sum()
        assert len(qsequence) > 0
        total_exact_change_points += (len(qsequence) - 1)

  result_dict = {
      'total_weights': total_weights,
      'correct_weight_sequences': correct_weight_sequences,
      'total_q_oscillation': total_q_oscillation,
      'total_i_oscillation': total_i_oscillation,
      'total_oscillation_error': total_oscillation_error,
      'total_step_count_error': total_step_count_error,
      'total_compressed_change_points': total_compressed_change_points,
      'exact_correct_weight_sequences': exact_correct_weight_sequences,
      'total_exact_step_count_error': total_exact_step_count_error,
      'total_exact_change_points': total_exact_change_points,
    }

  return result_dict


def sanitize_filename(s):
  return "".join(c for c in s if c.isalnum() or c in (' ', '.', '_')).rstrip()


def generate_filename(func, *args, **kwargs):

  elts = []

  # Include the function name
  elts.append(func.__name__)

  # Include positional arguments
  for arg in args:
    elts.append(str(arg))

  # Include keyword arguments
  for k, v in kwargs.items():
    elts.append(str(k))
    elts.append(str(v))

  st = sanitize_filename(''.join(elts))
  filename_chars = list(st)
  seed = sum(ord(ch) for ch in filename_chars)
  random.seed(seed)
  random.shuffle(filename_chars)
  filename = ''.join(filename_chars[:50])

  # return os.path.join('data', sanitize_filename(m.hexdigest() + ".pkl"))
  return sanitize_filename(filename + ".pkl")


def save_or_load_output(func, *args, actual_args=None,
                        actual_kwargs=None, path=None, **kwargs):
  filename = generate_filename(func, *args, **kwargs)

  if actual_args is not None:
    args = actual_args
  if actual_kwargs is not None:
    kwargs = actual_kwargs

  if path is not None:
    filename = os.path.join(path, filename)

  print(filename)

  # Check if the file already exists
  if os.path.exists(filename):
    # Load and return the precomputed output
    with open(filename, 'rb') as f:
      return pickle.load(f)
  else:
    # Compute the output
    output = func(*args, **kwargs)

    # Save the output to a file
    with open(filename, 'wb') as f:
      pickle.dump(output, f)

    return output


def get_inference_results(quantizer_warp_data, initializer_warp_data):
  res = {}

  tf.debugging.assert_equal(
      quantizer_warp_data['correct_output_values'], initializer_warp_data['correct_output_values'])

  qpredictions = np.argmax(quantizer_warp_data['model_predictions'], axis=1)
  ipredictions = np.argmax(initializer_warp_data['model_predictions'], axis=1)

  res['quantizer_model_accuracy'] = (
      qpredictions == initializer_warp_data['correct_output_values']).mean()
  res['initializer_model_accuracy'] = (
      ipredictions == initializer_warp_data['correct_output_values']).mean()

  inference_agreement_total = (qpredictions == ipredictions).sum()
  res['inference_agreement_proportion'] = inference_agreement_total / \
      len(qpredictions)

  incorrect_inference_agreement_total = ((qpredictions == ipredictions)
                                         & (ipredictions != quantizer_warp_data['correct_output_values'])
                                         & (qpredictions != quantizer_warp_data['correct_output_values'])
                                         ).sum()
  res['incorrect_inference_agreement_proportion'] = incorrect_inference_agreement_total / \
      ((ipredictions != quantizer_warp_data['correct_output_values']) & (
          qpredictions != quantizer_warp_data['correct_output_values'])).sum()

  res['logit_mse'] = np.sum((quantizer_warp_data['model_predictions'] -
                            initializer_warp_data['model_predictions']) ** 2) / quantizer_warp_data['model_predictions'].size

  res['avg_logit_difference'] = np.sum(np.abs(quantizer_warp_data['model_predictions'] -
                                       initializer_warp_data['model_predictions'])) / quantizer_warp_data['model_predictions'].size

  return res


def plot_data(history1, history2, metric, label1, label2, path, 
  linewidth=0.5, offset=0, name=""):
  # Create subplots
  _, axs = plt.subplots(1, 2, figsize=(12, 4))

  prettify = {
    'loss': 'Loss',
    'val_loss': 'Validation Loss',
    'val_accuracy': 'Validation Accuracy',
  }

  # Plot raw data
  axs[0].plot(history1[metric][offset:], label=label1,
              linewidth=linewidth, color='purple', alpha=0.7)
  axs[0].plot(history2[metric][offset:], label=label2,
              linewidth=linewidth, color='red', linestyle='--', alpha=0.7)
  axs[0].set_title(f'{prettify[metric]} (Raw Data)')
  axs[0].set_ylabel(prettify[metric])
  axs[0].set_xlabel('Epoch')
  axs[0].legend(loc='upper left')

  # Plot difference between curves
  difference = [a - b for a,
                b in zip(history1[metric][offset:], history2[metric][offset:])]
  axs[1].plot(difference, label=f'{label1} - {label2}',
              linewidth=linewidth, color='blue', alpha=0.7)

  # Add line at zero
  axs[1].axhline(0, color='grey', linestyle='--', linewidth=linewidth)

  axs[1].set_title(f'{prettify[metric]} (Difference)')
  axs[1].set_ylabel('Difference')
  axs[1].set_xlabel('Epoch')
  axs[1].legend(loc='upper left')

  # Save the plot
  plt.savefig(os.path.join(path, f"{name}_{metric}.png"))

  # Show correlation
  correlation, _ = pearsonr(
      history1[metric][offset:], history2[metric][offset:])
  return {f"{metric}_correlation": correlation}


def get_history_data(quantizer_warp_history, initializer_warp_history, name, *, path):
  offset = 0
  linewidth = 0.5
  res = {}
  res.update(plot_data(quantizer_warp_history, initializer_warp_history, 'loss',
                       '$\hat Q$ Model Train Loss', 'STE Model Train Loss', 
                       path, linewidth, offset, name))

  res.update(plot_data(quantizer_warp_history, initializer_warp_history, 'val_loss',
                       '$\hat Q$ Model Test Loss', 'STE Model Test Loss', 
                       path, linewidth, offset, name))

  res.update(plot_data(quantizer_warp_history, initializer_warp_history, 'val_accuracy',
                       '$\hat Q$ Model Test Accuracy', 'STE Model Test Accuracy', 
                       path, linewidth, offset, name))

  return res


def get_change_point_results(change_point_res, quantizer_warp_data):

  res = {}

  res['correct_sequences_proportion'] = change_point_res['correct_weight_sequences'] / \
      change_point_res['total_weights']
  res['total_q_oscillation'] = change_point_res["total_q_oscillation"]
  res['total_i_oscillation'] = change_point_res["total_i_oscillation"]
  res['average_oscillation_error'] = change_point_res['total_oscillation_error'] / \
      change_point_res['total_compressed_change_points']
  res['average_step_count_error'] = change_point_res['total_step_count_error'] / \
      change_point_res['total_compressed_change_points']
  res['total_steps'] = quantizer_warp_data['total_batches']

  res['exact_correct_sequences_proportion'] = change_point_res['exact_correct_weight_sequences'] / \
      change_point_res['total_weights']
  res['average_exact_step_count_error'] = change_point_res['total_exact_step_count_error'] / \
      change_point_res['total_exact_change_points']

  return res


def compute_distance_metric(
  qstored_weights, istored_weights, istored_distances, initializer, quantizer):

  assert qstored_weights.keys() == istored_weights.keys() == istored_distances.keys()

  distances = {}
  quantized_agreements = {}

  for key in qstored_weights:
    total_sum = 0.0
    total_weights = 0
    total_qweight_agreements = 0
    for qstored_weight, istored_weight in zip(qstored_weights[key], istored_weights[key]):
      max_val = get_he_uniform_max_val(qstored_weight.shape)
      _ = initializer(qstored_weight.shape)
      total_sum += tf.math.reduce_sum(
          tf.abs(initializer.remap(qstored_weight) - istored_weight) / max_val)
      quantizer.set_shape(qstored_weight.shape)
      total_weights += qstored_weight.size
      total_qweight_agreements += tf.math.reduce_sum(
        tf.keras.backend.cast_to_floatx(quantizer(qstored_weight) == quantizer(istored_weight)))

    distances[key] = (total_sum / istored_distances[key]).numpy()
    quantized_agreements[key] = (total_qweight_agreements / total_weights).numpy()

  return distances, quantized_agreements


def get_initializer(identifier_kwargs):

  seed = 42

  if identifier_kwargs['warp_initialize']:
    if identifier_kwargs['binary']:
      warp_initializer = tanh_binary_initializer(seed, identifier_kwargs['k'])
    else:
      warp_initializer = dsq_multi_bit_initializer(
          seed, identifier_kwargs['bits'], identifier_kwargs['k'])
  else:
    warp_initializer = ste_initializer(seed)

  return warp_initializer

def _get_quantizer(identifier_kwargs):

  if identifier_kwargs['binary']:
    quantizer = tanh_binary_quantizer(identifier_kwargs['k'])
  else:
    quantizer = dsq_multi_bit_quantizer(
      identifier_kwargs['bits'], identifier_kwargs['k'])
  return quantizer


def get_distance_metric(quantizer_warp_data, initializer_warp_data, identifier_kwargs):

  warp_initializer = get_initializer(identifier_kwargs)
  quantizer = _get_quantizer(identifier_kwargs)
  distances, quantized_agreements = compute_distance_metric(
      quantizer_warp_data['stored_weights'],
      initializer_warp_data['stored_weights'],
      initializer_warp_data['stored_distances'],
      warp_initializer,
      quantizer
  )

  return {'distance_metric': distances, 'quantized_agreements': quantized_agreements}


def get_flattened_latent_weights(weights, decapitate=True, initializer=None):

  weight_ls = []
  for i, weight in enumerate(weights):
    if i < len(weights) - 2 or (not decapitate):
      if initializer is not None:
        _ = initializer(weight.shape)
        weight = initializer.remap(weight)
      weight = weight / get_he_uniform_max_val(weight.shape)
      weight_ls.append(np.array(weight).flatten())

  return np.concatenate(weight_ls)


def plot_weight_alignment_and_movement(
    quantizer_warp_data, initializer_warp_data, identifier_kwargs, *, path, name=""):
  res = {}
  warp_initializer = get_initializer(identifier_kwargs)
  s = 1

  plt.clf()
  # Create the Weight Alignment plot
  plt.scatter(
      get_flattened_latent_weights(quantizer_warp_data['weights_final']),
      get_flattened_latent_weights(initializer_warp_data['weights_final']),
      label='Raw weights', s=s
  )
  plt.scatter(
      get_flattened_latent_weights(
          quantizer_warp_data['weights_final'], initializer=warp_initializer),
      get_flattened_latent_weights(initializer_warp_data['weights_final']),
      label='$I_{\\hat Q}$(weights)', s=s
  )
  plt.xlabel('$\\hat Q$ model weights')
  plt.ylabel('STE model weights')
  plt.title("Weight Alignment")
  plt.legend()

  # Save the Weight Alignment plot
  plt.savefig(os.path.join(path, f"{name}_Weight_Alignment.png"))
  plt.clf()

  # Create the Weight Movement plot
  plt.scatter(
      get_flattened_latent_weights(initializer_warp_data['weights_init']),
      get_flattened_latent_weights(initializer_warp_data['weights_final']), s=s
  )
  plt.xlabel('Initial STE Model weights')
  plt.ylabel('Final  STE Model weights')
  plt.title("Weight Movement")

  # Save the Weight Movement plot
  plt.savefig(os.path.join(path, f"{name}_Weight_Movement.png"))
  plt.clf()

  # Assuming you want to return some results, you can populate the 'res' dictionary here
  # For example, you might want to calculate and return some statistics about the weights
  # res['some_statistic'] = calculate_some_statistic(quantizer_warp_data, initializer_warp_data)

  return res


def convert_all_float32_to_float(d):
  if isinstance(d, dict):
    return {k: convert_all_float32_to_float(v) for k, v in d.items()}
  elif isinstance(d, list):
    return [convert_all_float32_to_float(v) for v in d]
  elif isinstance(d, np.float32):
    return float(d)
  else:
    return d



def run_analysis_for_one(quantizer_warp_data, initializer_warp_data,
                         identifier_kwargs, name, path, cache_data=True):

  res = {}

  if config['get_change_point_stats']:
    if cache_data:
      actual_args = [
          quantizer_warp_data['change_points'],
          initializer_warp_data['change_points']
      ]
      actual_kwargs = {}
      change_point_res = save_or_load_output(
          compare_change_point_data, **identifier_kwargs, actual_args=actual_args,
          actual_kwargs=actual_kwargs, path=path
      )
    else:
      change_point_res = compare_change_point_data(
          quantizer_warp_data, initializer_warp_data)

    change_point_results = get_change_point_results(
        change_point_res, quantizer_warp_data)
    res.update(change_point_results)
    
  inference_results = get_inference_results(
      quantizer_warp_data, initializer_warp_data)
  res.update(inference_results)

  history_data = get_history_data(
      quantizer_warp_data['history'], initializer_warp_data['history'], name=name, path=path)
  res.update(history_data)

  distance_metric = get_distance_metric(
      quantizer_warp_data, initializer_warp_data, identifier_kwargs)
  res.update(distance_metric)

  plot_weight_alignment_and_movement(
      quantizer_warp_data, initializer_warp_data, identifier_kwargs, name=name, path=path)

  return res


def get_default_kwargs(config):

  default_kwargs = {
      'learning_rate': CosineDecay,
      'epochs': config['sgd_epochs'],
      'optimizer': keras.optimizers.SGD,
      'binary': False,
      'warp_initialize': True,
      'simple': False,
      'optimizer_kwargs': {'momentum': 0.9},
      'k': config['bit_to_k_map'][config['default_bits']],
      'bits': config['default_bits'],
      'steps_per_epoch': config['steps_per_epoch'],
      'weight_decay': config['weight_decay'],
      'lr_kwargs': {
          'initial_learning_rate': 0.0,
          'warmup_target': config['sgd_lr'],
          'warmup_steps': config['steps_per_epoch'] * config['warmup_proportion'] * config['sgd_epochs'],
          'decay_steps': config['steps_per_epoch'] * (1 - config['warmup_proportion']) * config['sgd_epochs']
      }
  }

  return default_kwargs


def get_train_kwargs(config, optimizer_type, jitter=False, scaledown=False):
  if optimizer_type == 'sgd':
    lr = config['sgd_lr']
    epochs = config['sgd_epochs']
    optimizer = keras.optimizers.SGD
    optimizer_kwargs = {'momentum': 0.9}
    warp_initialize = True
  elif optimizer_type == 'adam':
    lr = config['adam_lr']
    epochs = config['adam_epochs']
    optimizer = keras.optimizers.Adam
    optimizer_kwargs = {'beta_2': 0.95}
    warp_initialize = False
  else:
    raise ValueError("Invalid optimizer_type. Must be either 'sgd' or 'adam'.")

  weight_decay = config['weight_decay']

  if jitter:
    lr = lr * (1.0 + config['lr_jitter_scale'])
    warp_initialize = False
  if scaledown:
    lr = lr * config['lr_scaledown']
    epochs *= config['epoch_scale_up_for_lr_scale_down']
    weight_decay *= config['lr_scaledown']

  updates = {
      'learning_rate': CosineDecay,
      'epochs': epochs,
      'lr_kwargs': {
          'initial_learning_rate': 0.0,
          'warmup_target': lr,
          'warmup_steps': config['steps_per_epoch'] * config['warmup_proportion'] * epochs,
          'decay_steps': config['steps_per_epoch'] * (1 - config['warmup_proportion']) * epochs
      },
      'optimizer': optimizer,
      'optimizer_kwargs': optimizer_kwargs,
      'warp_initialize': warp_initialize,
      'weight_decay': weight_decay,
  }

  default_kwargs = get_default_kwargs(config)

  kwargs = default_kwargs.copy()
  kwargs.update(updates)

  return kwargs

def get_quantizer_kwargs(config, bits):

  updates = {
      'k': config['bit_to_k_map'][bits],
      'bits': bits,
  }

  default_kwargs = get_default_kwargs(config)

  kwargs = default_kwargs.copy()
  kwargs.update(updates)

  return kwargs


def run_models_from_kwargs(kwargs, config):

  if config['cache_data']:
    quantizer_warp_data, initializer_warp_data = save_or_load_output(
        train_corresponding_models, **kwargs, path=config['path']
    )
  else:
    quantizer_warp_data, initializer_warp_data = train_corresponding_models(**kwargs)

  return quantizer_warp_data, initializer_warp_data


def run_full_analysis(config):

  if not os.path.exists(config['path']):
    # make directory
    os.makedirs(config['path'])

  res = {}
  optimizer_types = ['sgd', 'adam']

  # run models for both optimizers
  for opt_type in optimizer_types:
    kwargs = get_train_kwargs(config, opt_type)
    quantizer_warp_data, initializer_warp_data = run_models_from_kwargs(
        kwargs, config)
    results = run_analysis_for_one(
        quantizer_warp_data,
        initializer_warp_data,
        kwargs,
        opt_type,
        cache_data=config['cache_data'],
        path=config['path'])
    res[opt_type] = results

    jitter_kwargs = get_train_kwargs(config, opt_type, jitter=True)
    quantizer_warp_data_jitter, _ = run_models_from_kwargs(jitter_kwargs, config)
    jitter_results = run_analysis_for_one(
        quantizer_warp_data,
        quantizer_warp_data_jitter,
        jitter_kwargs,
        f"{opt_type}_jitter",
        cache_data=config['cache_data'],
        path=config['path'])
    res[f"{opt_type}_jitter"] = jitter_results

    scaledown_kwargs = get_train_kwargs(config, opt_type, scaledown=True)
    quantizer_warp_data_scaledown, initializer_warp_data_scaledown = run_models_from_kwargs(
        scaledown_kwargs, config)
    scaledown_results = run_analysis_for_one(
        quantizer_warp_data_scaledown,
        initializer_warp_data_scaledown,
        scaledown_kwargs,
        f"{opt_type}_scaledown",
        cache_data=config['cache_data'],
        path=config['path'])
    res[f"{opt_type}_scaledown"] = scaledown_results

  # run without warp_initialize for sgd
  no_warp_kwargs = get_train_kwargs(config, 'sgd')
  no_warp_kwargs['warp_initialize'] = False
  quantizer_warp_data, initializer_warp_data = run_models_from_kwargs(
        no_warp_kwargs, config)
  no_warp_results = run_analysis_for_one(
      quantizer_warp_data,
      initializer_warp_data,
      no_warp_kwargs,
      'sgd_no_warp',
      cache_data=config['cache_data'],
      path=config['path'])
  res['sgd_no_warp'] = no_warp_results

  # run models for other bits
  for bits in config['other_bits']:
    bits_kwargs = get_quantizer_kwargs(config, bits)
    quantizer_warp_data, initializer_warp_data = run_models_from_kwargs(
        bits_kwargs, config)
    bits_results = run_analysis_for_one(
        quantizer_warp_data,
        initializer_warp_data,
        bits_kwargs,
        f"{bits}_bits",
        cache_data=config['cache_data'],
        path=config['path'])

    res[f"{bits}_bits"] = bits_results

  res = convert_all_float32_to_float(res)

  with open(os.path.join(config['path'], 'results.json'), 'w') as f:
    json.dump(res, f)

  return res

def read_config_from_directory(directory, config_filename='config.py'):
  config_path = os.path.join(directory, config_filename)
  
  if not os.path.exists(config_path):
    raise FileNotFoundError(f"Config file not found in directory {directory}. Please make sure '{config_filename}' exists.")
  
  # Add the directory to sys.path
  sys.path.append(directory)
  
  # Dynamically import the config module
  spec = importlib.util.spec_from_file_location("config", config_path)
  config_module = importlib.util.module_from_spec(spec)
  spec.loader.exec_module(config_module)
  
  # Remove the directory from sys.path
  sys.path.remove(directory)
  
  config = config_module.config
  
  # Add the path to the config dictionary
  config['path'] = directory
  
  return config

if __name__ == '__main__':
  parser = argparse.ArgumentParser(description='Run analysis with config from a directory.')
  parser.add_argument('directory', type=str, help='Directory where config.py is located.')
  
  args = parser.parse_args()
  
  try:
    config = read_config_from_directory(args.directory)
    res = run_full_analysis(config)
    pprint(res)
  except FileNotFoundError as e:
    print(e)
    print("Please provide a directory containing 'config.py'.")

